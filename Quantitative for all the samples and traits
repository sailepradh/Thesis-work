## Doing the removal of the samples in the maxmissing vcf files

vcftools --vcf maxmiss.vcf --remove sample_remove --recode --out maxmiss.filter

Numbr of variant = 149615

plinkseq-0.10/pseq ben new-project --resources hg19
plinkseq-0.10/pseq ben load-vcf --vcf data/maxmiss.filter.recode.vcf 

######################################################################
########Manipulating the phenotype data in the R and doing the phenotype information of the patients

pheno<-read.csv("pheno.csv", header=TRUE, sep =",")
pheno[c("LOG_TPK","LOG_Lpk","LOG_neu")] <- c(log(pheno$Nadir_TPK),
                                             log(pheno$Nadir_LPK), 
                                             log(pheno$Nadir_Neutrophiles))

pheno$Patient.ID<-as.factor(gsub("[_]","", pheno$Patient.ID))
## Removing the samples foles S0328, S0664, S0580, S0922, S0363 from the phenotype data 
## provided to us such that only individuals with the exome sequencing data are present.

pheno_trim<-pheno[!pheno$Patient.ID %in% c("S0328","S0580","S0631","S0664","S0667","S0724","S0922","S0363"),]
row.names(pheno_trim) <- NULL

pop<-pheno_trim[,c(1,25,26,27)]
pop$LOG_TPK<-round((pheno_trim$LOG_TPK),digit=2)
pop$LOG_Lpk<-round((pheno_trim$LOG_Lpk),digit=2)
pop$LOG_neu<-round((pheno_trim$LOG_neu),digit=2)
pop$LOG_neu[is.na(pop$LOG_neu)] <- -9
pop$LOG_neu[is.infinite(pop$LOG_neu)] <- -9
colnames(pop)<- c("#ID","Thr","Leu","Neu")
write.table(pop,"pop2.txt", sep="\t", quote = F, row.names = F)

#############################################################################################################
#############################################################################################################
## Histogram of the phenotypic data
hist(pop$LOG_neu,breaks=20,
     main="Distribution of log-converted Neutropenia ",
     ylab="Frequency of Neutropenia",
     xlab="Log converted nadir values \n",
     col="grey")
hist(pop$LOG_TPK,breaks=20, 
     col="Red",
     main="Distribution of log-converted Thrombopenia ",
     ylab="Frequency of Thrombopenia",
     xlab="Log converted nadir values \n"
     )
hist(pop$LOG_Lpk, breaks = 20, 
     col="Red",
     ain="Distribution of log-converted Leucopenia ",
     ylab="Frequency of Leucopenia",
     xlab="Log converted nadir values \n"
     )

#Your Data Compared to the Normal Distribution
#Draw Histogram, with a normal distribution over it
## For the thrombopenia score
#1) create our histogram, assign it to h, "h<-..."
h<-hist(pop$LOG_TPK,breaks=20,
     main="Distribution of log-converted Thrombopenia ",
     ylab="Frequency of Thrombopenia",
     xlab="Log converted nadir values \n",
     col="Grey")

#2) create 40 bins from our data:	
xfit <- seq(min(pheno_trim$LOG_TPK),max(pheno_trim$LOG_TPK),length=40)

#3) Given our data's mean and sd, find the normal distribution
yfit <- dnorm(xfit, mean=mean(pheno_trim$LOG_TPK),,sd=sd(pheno_trim$LOG_TPK))

#4) Fit the normal dist to our data
yfit<- yfit*diff(h$mids[1:2])*length(pheno_trim$LOG_TPK)

#5) Plot these lines. 
lines(xfit,yfit)

#Kernal Density Plots
density<-density(pheno_trim$LOG_TPK)
plot(density)

#fancy it up
plot(density,
     main="Kernal Density for Thrombopenia ",
     xlab="Log Nadir Thrombopenia",
     ylab="Density",
     col="red"
)
polygon(density,col="grey")



## For the leucopenia data 
#1) create our histogram, assign it to h, "h<-..."
h<-hist(pop$LOG_Lpk,breaks=20,
        main="Distribution of log-converted Leucopenia",
        ylab="Frequency of Leucopenia",
        xlab="Log converted nadir values \n",
        col="Grey")

#2) create 40 bins from our data:  
xfit <- seq(min(pheno_trim$LOG_Lpk),max(pheno_trim$LOG_Lpk),length=500)

#3) Given our data's mean and sd, find the normal distribution
yfit <- dnorm(xfit, mean=mean(pheno_trim$LOG_Lpk),,sd=sd(pheno_trim$LOG_Lpk))

#4) Fit the normal dist to our data
yfit<- yfit*diff(h$mids[1:2])*length(pheno_trim$LOG_Lpk)

#5) Plot these lines. 
lines(xfit,yfit)

#Kernal Density Plots
density<-density(pheno_trim$LOG_Lpk)
plot(density)

#fancy it up
plot(density,
     main="Kernal Density for Leucopenia ",
     xlab="Log Nadir Leucopenia",
     ylab="Density",
     col="red"
)
polygon(density,col="grey")



## For the Neutropenia data 
#1) create our histogram, assign it to h, "h<-..."
h<-hist(pop$LOG_neu,breaks=20,
        main="Distribution of log-converted Neutropenia",
        ylab="Frequency of Neutropenia",
        xlab="Log converted nadir values \n",
        col="Grey")

#2) create 40 bins from our data: 
range(pheno_trim$LOG_neu,na.rm=TRUE,finite=TRUE)
xfit <- seq(-2.407946,2.917771,length=1000)

#3) Given our data's mean and sd, find the normal distribution
test<-pheno_trim[!(is.na(pheno_trim$LOG_neu) | is.infinite(pheno_trim$LOG_neu)),]
yfit <- dnorm(xfit, mean=mean(test$LOG_neu),,sd=sd(test$LOG_neu))

#4) Fit the normal dist to our data
yfit<- yfit*diff(h$mids[1:2])*length(pheno_trim$LOG_Lpk)

#5) Plot these lines. 
lines(xfit,yfit)

#Kernal Density Plots
density<-density(pheno_trim$LOG_Lpk)
plot(density)

#fancy it up
plot(density,
     main="Kernal Density for Neutropenia ",
     xlab="Log Nadir Neutropenia",
     ylab="Density",
     col="red"
)
polygon(density,col="grey")
#####################################################
###########  END of the R code #####################

plinkseq-0.10/pseq ben load-pheno --file data/pop2.phe 
Processed 210 rows

Final phenotype data in data/pop2.phe
##Thr,Float,-9,”Thrombopenia trait 1"
##Leu,Float,-9,”Leucopenia trait 2”
##Neu,Float,-9,”Neutropenia trait 3”
#ID	Thr	Leu	Neu
S0143	4.42	1.28	0.69
S0156	3.43	0.34	-2.41
S0160	5.17	1.41	0.99
S0162	2.64	1.06	0.59
S0164	1.61	-2.3	-9
S0170	4.48	2.42	2.3
S0172	5.49	1.19	0.83


plinkseq-0.10/pseq ben loc-summary
plinkseq-0.10/pseq ben ref-summary
plinkseq-0.10/pseq ben seq-summary

### Doing the single variant association study for the each of the phenotype
plinkseq-0.10/pseq ben glm --phenotype Thr  > Single_variant_Thr
plinkseq-0.10/pseq ben glm --phenotype Leu  > Single_variant_leu
plinkseq-0.10/pseq ben glm --phenotype Neu  > Single_variant_Neu

sort -g -k9 Single_variant_Thr > Single_variant_Thr_2 
grep -v 'NA' Single_variant_Thr_2 > ./SKAT_RESULTS/Whole_Single_variant_Thr


sort -g -k9 Single_variant_leu > Single_variant_leu_2
grep -v 'NA' Single_variant_leu_2 > ./SKAT_RESULTS/Whole_Single_variant_Leu


sort -g -k9 Single_variant_Neu > Single_variant_Neu_2
grep -v 'NA' Single_variant_Neu_2 > ./SKAT_RESULTS/Whole_Single_variant_Neu


### Doing the association studies undertaking the ensembl database
plinkseq-0.10/pseq ben assoc --tests skat --phenotype Thr --mask loc.group=ensembl > SKAT_THR_ENSEMBL
plinkseq-0.10/pseq ben assoc --tests skat --phenotype Thr --mask loc.group=ensembl  mac=1-10 > Rare_SKAT_THR_ENSEMBL
## Doing the rare association considering the count to be 1-10 allele count 

plinkseq-0.10/pseq ben assoc --tests skat --phenotype Leu --mask loc.group=ensembl > SKAT_Leu_ENSEMBL
plinkseq-0.10/pseq ben assoc --tests skat --phenotype Leu --mask loc.group=ensembl  mac=1-10 > Rare_SKAT_Leu_ENSEMBL
## Doing the rare association considering the count to be 1-10 allele count 

plinkseq-0.10/pseq ben assoc --tests skat --phenotype Neu --mask loc.group=ensembl > SKAT_Neu_ENSEMBL
plinkseq-0.10/pseq ben assoc --tests skat --phenotype Neu --mask loc.group=ensembl  mac=1-10 > Rare_SKAT_Neu_ENSEMBL
## Doing the rare association considering the count to be 1-10 allele count 

## Further manipulation to get the desired result
 sort -g -k6 SKAT_THR_ENSEMBL > SKAT_THR_ENSEMBL_2
 tail -1000 SKAT_THR_ENSEMBL_2
 sed -n -e '/LOCUS/,/ENST00000585134/ p' SKAT_THR_ENSEMBL_2 > SKAT_THR_ENSEMBL_3
 
 sed -n -e '/LOCUS/,/ENST00000585004/ p' Rare_SKAT_THR_ENSEMBL_2 > ./SKAT_RESULTS/Variant_MAC_1_10_SKAT_THR_ENSEMBL
 ## Rare count frm 1-10 

 
 sort -g -k6 SKAT_Leu_ENSEMBL > SKAT_Leu_ENSEMBL_2
 tail SKAT_Leu_ENSEMBL_2
 sed -n -e '/LOCUS/,/ENST00000585223/p' SKAT_Leu_ENSEMBL_2 > SKAT_Leu_ENSEMBL_3 
 
sed -n -e '/LOCUS/,/ENST00000585169/p' Rare_SKAT_Leu_ENSEMBL_2 > ./SKAT_RESULTS/Variant_MAC_1_10_SKAT_Leu_ENSEMBL
 ## Rare count frm 1-10 	
 
 sort -g -k6 SKAT_Neu_ENSEMBL > SKAT_Neu_ENSEMBL_2
 tail SKAT_Neu_ENSEMBL_2
 sed -n -e '/LOCUS/,/ENST00000585277/p' SKAT_Neu_ENSEMBL_2 > ./SKAT_RESULTS/Whole_Variant_Neu_ENSEMBL 
 
 sed -n -e '/LOCUS/,/ENST00000585169/p' Rare_SKAT_Neu_ENSEMBL_2 > ./SKAT_RESULTS/Variant_MAC_1_10_SKAT_Neu_ENSEMBL
  ## Rare count frm 1-10 
 

### Doing the association using the REFSEQ database
plinkseq-0.10/pseq ben assoc --tests skat --phenotype Thr --mask loc.group=refseq > SKAT_THR_Refseq
plinkseq-0.10/pseq ben assoc --tests skat --phenotype Leu --mask loc.group=refseq > SKAT_Leu_Refseq
plinkseq-0.10/pseq ben assoc --tests skat --phenotype Neu --mask loc.group=refseq > SKAT_Neu_Refseq


## Further manipulation to get the desired result
 awk -F"\t" -v OFS="\t" '{ for(N=1; N<=NF; N++) if($6=="") $6="NA" } 1' SKAT_THR_Refseq > SKAT_THR_Refseq_2 
 grep -v 'NA' SKAT_THR_Refseq_2 > SKAT_THR_Refseq_3
 sort -g -k6 SKAT_THR_Refseq_3 > SKAT_RESULTS/Whole_Variant_SKAT_THR_Ref
 
 awk -F"\t" -v OFS="\t" '{ for(N=1; N<=NF; N++) if($6=="") $6="NA" } 1' SKAT_Leu_Refseq > SKAT_Leu_Refseq_2 
 grep -v 'NA' SKAT_Leu_Refseq_2 > SKAT_Leu_Refseq_3
 sort -g -k6 SKAT_Leu_Refseq_3 > SKAT_RESULTS/Whole_Variant_SKAT_Leu_Ref
 
  awk -F"\t" -v OFS="\t" '{ for(N=1; N<=NF; N++) if($6=="") $6="NA" } 1' SKAT_Neu_Refseq > SKAT_Neu_Refseq_2 
 grep -v 'NA' SKAT_Neu_Refseq_2 > SKAT_Neu_Refseq_3
 sort -g -k6 SKAT_Neu_Refseq_3 > SKAT_RESULTS/Whole_Variant_SKAT_Neu_Ref

 ##############################################################################################################
 ###############################################################################################################
  For the variants with the MAF > 0.01 we first get the variants from the previously processed vcf files of maxmiss.filter.recode.vcf. 
  
cat maxmiss.filter.log

Parameters as interpreted:
	--vcf maxmiss.vcf
	--exclude sample_remove
	--out maxmiss.filter
	--recode

Excluding individuals in 'exclude' list
After filtering, kept 210 out of 216 Individuals
Outputting VCF file...
After filtering, kept 151985 out of a possible 151985 Sites
 
So for getting the vcf files with the variants at 0.01 we used the following command in weexport for the easy sake
vcftools --vcf maxmiss.filter.recode.vcf --maf 0.01 --recode --out maxmiss.0.01

Total Variant = 74018 (different from the one from the Benzamin may be different in the plink and plinkseq)
plinkseq-0.10/pseq Common new-project --resources hg19
 plinkseq-0.10/pseq Common load-vcf --vcf ./data/maxmiss.0.01.recode.vcf 
 plinkseq-0.10/pseq Common tag-file --id 1 --name Common
  plinkseq-0.10/pseq Common var-summary
  
  plinkseq-0.10/pseq Common load-pheno --file data/pop2.phe 
  
  plinkseq-0.10/pseq Common i-view
  
  plinkseq-0.10/pseq Common loc-summary
  plinkseq-0.10/pseq Common ref-summary
   plinkseq-0.10/pseq Common seq-summary

### Doing the single variant association study for the each of the phenotype
plinkseq-0.10/pseq Common glm --phenotype Thr  > Single_variant_Common_Thr
plinkseq-0.10/pseq Common glm --phenotype Leu  > Single_variant_Common_leu
plinkseq-0.10/pseq Common glm --phenotype Neu  > Single_variant_Common_Neu

sort -g -k9 Single_variant_Common_Thr > Single_variant_Common_Thr_2 
grep -v 'NA' Single_variant_Common_Thr_2 > ./SKAT_RESULTS/Common_Single_variant_Thr


sort -g -k9 Single_variant_Common_leu > Single_variant_Common_leu_2
grep -v 'NA' Single_variant_Common_leu_2 > ./SKAT_RESULTS/Common_Single_variant_Leu


sort -g -k9 Single_variant_Common_Neu > Single_variant_Common_Neu_2
grep -v 'NA' Single_variant_Common_Neu_2 > ./SKAT_RESULTS/Common_Single_variant_Neu


plinkseq-0.10/pseq Common assoc --tests skat --phenotype Thr --mask loc.group=ensembl > Common_SKAT_THR_ENSEMBL
plinkseq-0.10/pseq Common assoc --tests skat --phenotype Leu --mask loc.group=ensembl > Common_SKAT_Leu_ENSEMBL
plinkseq-0.10/pseq Common assoc --tests skat --phenotype Neu --mask loc.group=ensembl > Common_SKAT_Neu_ENSEMBL

## Further manipulation to get the desired result
 sort -g -k6 Common_SKAT_THR_ENSEMBL > Common_SKAT_THR_ENSEMBL_2
 head Common_SKAT_THR_ENSEMBL_2
 tail Common_SKAT_THR_ENSEMBL_2
 sed -n -e '/LOCUS/,/ENST00000585217/p' Common_SKAT_THR_ENSEMBL_2 > SKAT_RESULTS/Common_SKAT_THR

 
  sort -g -k6 Common_SKAT_Neu_ENSEMBL > Common_SKAT_Neu_ENSEMBL_2
   head Common_SKAT_Neu_ENSEMBL_2 
   tail Common_SKAT_Neu_ENSEMBL_2
   sed -n -e '/LOCUS/,/ENST00000585141/p' Common_SKAT_Neu_ENSEMBL_2 > SKAT_RESULTS/Common_SKAT_Neu

sort -g -k6 Common_SKAT_Leu_ENSEMBL > Common_SKAT_Leu_ENSEMBL_2 
head Common_SKAT_Leu_ENSEMBL_2
 sed -n -e '/LOCUS/,/ENST00000585223/p' Common_SKAT_Leu_ENSEMBL_2 > SKAT_RESULTS/Common_SKAT_Leu



plinkseq-0.10/pseq Common assoc --tests skat --phenotype Thr --mask loc.group=refseq > Common_SKAT_THR_Refseq
plinkseq-0.10/pseq Common assoc --tests skat --phenotype Leu --mask loc.group=refseq > Common_SKAT_Leu_Refseq
plinkseq-0.10/pseq Common assoc --tests skat --phenotype Neu --mask loc.group=refseq > Common_SKAT_Neu_Refseq

 ## Further manipulation to get the desired result
 awk -F"\t" -v OFS="\t" '{ for(N=1; N<=NF; N++) if($6=="") $6="NA" } 1' Common_SKAT_THR_Refseq > Common_SKAT_THR_Refseq_2 
 grep -v 'NA' Common_SKAT_THR_Refseq_2 > Common_SKAT_THR_Refseq_3
 sort -g -k6 Common_SKAT_THR_Refseq_3 > SKAT_RESULTS/Common_SKAT_THR_Ref
 
 awk -F"\t" -v OFS="\t" '{ for(N=1; N<=NF; N++) if($6=="") $6="NA" } 1' Common_SKAT_Leu_Refseq > Common_SKAT_Leu_Refseq_2 
 grep -v 'NA' Common_SKAT_Leu_Refseq_2 > Common_SKAT_Leu_Refseq_3
 sort -g -k6 Common_SKAT_Leu_Refseq_3 > SKAT_RESULTS/Common_SKAT_Leu_Ref
 
  awk -F"\t" -v OFS="\t" '{ for(N=1; N<=NF; N++) if($6=="") $6="NA" } 1' Common_SKAT_Neu_Refseq > Common_SKAT_Neu_Refseq_2 
 grep -v 'NA' Common_SKAT_Neu_Refseq_2 > Common_SKAT_Neu_Refseq_3
 sort -g -k6 Common_SKAT_Neu_Refseq_3 > SKAT_RESULTS/Common_SKAT_THR_Ref
 




